{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "from pathlib import Path\n",
    "import urllib.request as ureq\n",
    "from os import unlink as os_unlink\n",
    "from tempfile import NamedTemporaryFile\n",
    "\n",
    "# Third-party libraries\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# --- PySparklibraries --- #\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import ltrim, rtrim\n",
    "from pyspark.ml.linalg import DenseMatrix, Vectors\n",
    "\n",
    "from pyspark.ml.stat import ChiSquareTest, Correlation\n",
    "from pyspark.mllib.feature import StandardScaler, VectorAssembler\n",
    "from pyspark.mllib.regression import LinearRegression, LogisticRegressionWithSGD\n",
    "\n",
    "from pyspark.sql.dataframe import DataFrame # For type assertion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "APP_NAME: str = \"census_income\"\n",
    "DATA_SUBDIR: Path = Path().joinpath(r\"data\")\n",
    "DATA_URL: str = \"https://github.com/PacktPublishing/PySpark-Cookbook/raw/master/Data/census_income.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(APP_NAME).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: integer (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- education-num: integer (nullable = true)\n",
      " |-- marital-status: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- capital-gain: integer (nullable = true)\n",
      " |-- capital-loss: integer (nullable = true)\n",
      " |-- hours-per-week: integer (nullable = true)\n",
      " |-- native-country: string (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      "\n",
      "['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'label']\n"
     ]
    }
   ],
   "source": [
    "def create_csv_dataframe(url: str) -> DataFrame:\n",
    "    \"\"\"Create and return pyspark DataFrame object from raw csv file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        Path to remote, internet-hosted data file.\n",
    "    verbose : bool\n",
    "        Whether or not to send additional info to stdout.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    filepath : str\n",
    "        Path to local temporary file.\n",
    "    DataFrame\n",
    "        pyspark.sql.dataframe.DataFrame object.\n",
    "    \"\"\"\n",
    "    if not DATA_SUBDIR.exists():\n",
    "        DATA_SUBDIR.mkdir()\n",
    "    \n",
    "    with ureq.urlopen(url) as resp:\n",
    "        tmp = resp.read().decode(\"utf-8\")\n",
    "        if tmp:\n",
    "            # Get data into temp file.\n",
    "            tempf = NamedTemporaryFile(mode=\"w\", encoding=\"utf-8\", dir = DATA_SUBDIR, delete = False)\n",
    "            tempf.write(tmp)\n",
    "            tempf.seek(0)            \n",
    "            tempf.close()\n",
    "            \n",
    "            # Create dataframe object and check type.\n",
    "            df_ = spark.read.csv(tempf.name, inferSchema = True, header = True)\n",
    "            assert (type(df_) == DataFrame), \"Data object type error.\"\n",
    "            \n",
    "            return df_\n",
    "\n",
    "dataset = create_csv_dataframe(DATA_URL)\n",
    "\n",
    "# https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.DataFrame.html#pyspark.sql.DataFrame\n",
    "if dataset:\n",
    "    dataset.printSchema()\n",
    "    print(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32561"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col, _type in dataset.dtypes:\n",
    "    if _type == \"string\":\n",
    "        dataset = dataset.withColumn(col, ltrim(rtrim(dataset[col])))\n",
    "\n",
    "# Print row count.\n",
    "dataset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+------+---------+-------------+--------------------+-----------------+-------------+-----+------+------------+------------+--------------+--------------+-----+\n",
      "|age|       workclass|fnlwgt|education|education-num|      marital-status|       occupation| relationship| race|   sex|capital-gain|capital-loss|hours-per-week|native-country|label|\n",
      "+---+----------------+------+---------+-------------+--------------------+-----------------+-------------+-----+------+------------+------------+--------------+--------------+-----+\n",
      "| 39|       State-gov| 77516|Bachelors|           13|       Never-married|     Adm-clerical|Not-in-family|White|  Male|        2174|           0|            40| United-States|<=50K|\n",
      "| 50|Self-emp-not-inc| 83311|Bachelors|           13|  Married-civ-spouse|  Exec-managerial|      Husband|White|  Male|           0|           0|            13| United-States|<=50K|\n",
      "| 38|         Private|215646|  HS-grad|            9|            Divorced|Handlers-cleaners|Not-in-family|White|  Male|           0|           0|            40| United-States|<=50K|\n",
      "| 53|         Private|234721|     11th|            7|  Married-civ-spouse|Handlers-cleaners|      Husband|Black|  Male|           0|           0|            40| United-States|<=50K|\n",
      "| 28|         Private|338409|Bachelors|           13|  Married-civ-spouse|   Prof-specialty|         Wife|Black|Female|           0|           0|            40|          Cuba|<=50K|\n",
      "| 37|         Private|284582|  Masters|           14|  Married-civ-spouse|  Exec-managerial|         Wife|White|Female|           0|           0|            40| United-States|<=50K|\n",
      "| 49|         Private|160187|      9th|            5|Married-spouse-ab...|    Other-service|Not-in-family|Black|Female|           0|           0|            16|       Jamaica|<=50K|\n",
      "| 52|Self-emp-not-inc|209642|  HS-grad|            9|  Married-civ-spouse|  Exec-managerial|      Husband|White|  Male|           0|           0|            45| United-States| >50K|\n",
      "| 31|         Private| 45781|  Masters|           14|       Never-married|   Prof-specialty|Not-in-family|White|Female|       14084|           0|            50| United-States| >50K|\n",
      "| 42|         Private|159449|Bachelors|           13|  Married-civ-spouse|  Exec-managerial|      Husband|White|  Male|        5178|           0|            40| United-States| >50K|\n",
      "+---+----------------+------+---------+-------------+--------------------+-----------------+-------------+-----+------+------------+------------+--------------+--------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workclass:  [Column<'workclass'>]\n",
      "education:  [Column<'education'>]\n",
      "marital-status:  [Column<'marital-status'>]\n",
      "occupation:  [Column<'occupation'>]\n",
      "relationship:  [Column<'relationship'>]\n",
      "race:  [Column<'race'>]\n",
      "sex:  [Column<'sex'>]\n",
      "native-country:  [Column<'native-country'>]\n",
      "label:  [Column<'label'>]\n"
     ]
    }
   ],
   "source": [
    "# Distinct values\n",
    "uniq_values: dict = {}\n",
    "for col, _type in dataset.dtypes:\n",
    "    if _type == \"string\":\n",
    "        uniq_values[col] = []\n",
    "        \n",
    "        uniq_values[col] = sorted(dataset.select(col).distinct())\n",
    "\n",
    "if len(uniq_values) > 0:\n",
    "    print(\"\\n\".join([f\"{k}:  {v}\" for k, v in uniq_values.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Female', 'Male']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# abc = dataset.dropDuplicates([\"sex\"]).select(\"sex\")\n",
    "# [r.sex for r in abc]\n",
    "tmp_table_name: str = \"census\"\n",
    "dataset.createOrReplaceTempView(tmp_table_name)\n",
    "\n",
    "_df = spark.sql(\"\"\"\n",
    "SELECT sex\n",
    "FROM census\n",
    "GROUP BY sex\n",
    "\"\"\")\n",
    "\n",
    "[r.sex for r in _df.collect()]\n",
    "\n",
    "# spark.catalog.dropTempView(tmp_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_pct = 0.75\n",
    "df_train, df_test = final_df.randomSplit([train_pct, 1-train_pct])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorized field\n",
    "dependent_variable: str = \"label\"\n",
    "features_col: str = \"features\"\n",
    "\n",
    "independent_variables = [i for i in dataset.columns if not i in (\"Email\", \"Address\", dependent_variable)]\n",
    "\n",
    "feature_assmblr = VectorAssembler(\n",
    "    inputCols = independent_variables,\n",
    "    outputCol = features_col\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear out dataset when done.\n",
    "spark.catalog.dropTempView(tmp_table_name)\n",
    "\n",
    "for f in DATA_SUBDIR.rglob(\"*\"):\n",
    "    _path = Path(f)\n",
    "    if _path.is_file():\n",
    "        _path.unlink()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
